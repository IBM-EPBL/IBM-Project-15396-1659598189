{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6ba6f0",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106f7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing keras library\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7831fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the image data generator\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa2eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the parameter for image generator class\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,rotation_range=180,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b4b6662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 436 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Applying image data generator functionality to train set \n",
    "x_train=train_datagen.flow_from_directory(r'D:\\IBM\\Dataset\\train_set',\n",
    "target_size=(128,128),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69cd2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Applying image data generator functionality to test set\n",
    "x_test=test_datagen.flow_from_directory(r'D:\\IBM\\Dataset\\test_set',\n",
    "target_size=(128, 128),batch_size=32,class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d1067a",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48943799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To define linear intialisation import Sequential \n",
    "from keras.models import Sequential\n",
    "#To add layers import Dense\n",
    "from keras.layers import Dense\n",
    "#To creat Convolution kernal import Convolution2D\n",
    "from keras.layers import Convolution2D\n",
    "#import Maxpooling layer\n",
    "from keras.layers import MaxPooling2D\n",
    "#import Flatten layer\n",
    "from keras.layers import Flatten\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8ee7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the model\n",
    "model=Sequential()\n",
    "#add convolution layer\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))\n",
    "#add maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#add convolution layer\n",
    "model.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "#add maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#add convolution layer\n",
    "model.add(Convolution2D(128,(3,3),activation='relu'))\n",
    "#add maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#add convolution layer\n",
    "model.add(Convolution2D(128,(3,3),activation='relu'))\n",
    "#add maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#add flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1281a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuring the learning process\n",
    "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a9e4175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.7029 - accuracy: 0.5757 - val_loss: 0.6005 - val_accuracy: 0.5950\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 46s 3s/step - loss: 0.5108 - accuracy: 0.7982 - val_loss: 0.2414 - val_accuracy: 0.9256\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.2793 - accuracy: 0.8784 - val_loss: 0.2167 - val_accuracy: 0.9091\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 48s 4s/step - loss: 0.2330 - accuracy: 0.8991 - val_loss: 0.0956 - val_accuracy: 0.9421\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 56s 4s/step - loss: 0.1715 - accuracy: 0.9197 - val_loss: 0.0257 - val_accuracy: 0.9917\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 58s 4s/step - loss: 0.1829 - accuracy: 0.9174 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 59s 4s/step - loss: 0.1714 - accuracy: 0.9289 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 57s 4s/step - loss: 0.1427 - accuracy: 0.9427 - val_loss: 0.0368 - val_accuracy: 0.9835\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 59s 4s/step - loss: 0.1397 - accuracy: 0.9427 - val_loss: 0.0314 - val_accuracy: 0.9917\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 58s 4s/step - loss: 0.1322 - accuracy: 0.9541 - val_loss: 0.0217 - val_accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "r=model.fit(x_train,epochs=10,validation_data=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aef9bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save(\"forestalert.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df61887",
   "metadata": {},
   "source": [
    "# Video Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddabad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twilio.rest import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "febc16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import load model from keras.model\n",
    "from keras.models import load_model\n",
    "#import image from keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import cv2\n",
    "#load the saved model\n",
    "model=load_model(r\"forestalert.h5\")\n",
    "img=image.load_img(r'D:\\IBM\\Dataset\\test_set\\with fire\\Uttarakhand_forest_fire.jpeg')\n",
    "x=image.img_to_array(img)\n",
    "# res=cv2.resize(x,dsize=(150,150),interpolation=cv2.INTER_CUBIC)\n",
    "#expand the image shape\n",
    "x=np.expand_dims(x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "121d6db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import WARNING\n",
    "#import opencv library\n",
    "import cv2\n",
    "#import numpy\n",
    "import numpy as np\n",
    "#import image function from keras\n",
    "from keras.preprocessing import image\n",
    "#import load_model from keras\n",
    "from keras.models import load_model\n",
    "#import client from twilio API\n",
    "from twilio.rest import Client\n",
    "#import playsound package\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82a20966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "video = cv2.VideoCapture(r'C:\\Users\\Dell\\Downloads\\forest trees.mp4')\n",
    "name=['forest','with fire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50339872",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(1):\n",
    " success,frame = video.read()\n",
    " cv2.imwrite(\"image.jpg\",frame)\n",
    " img = tensorflow.keras.utils.load_img(\"image.jpg\",target_size = (128,128))\n",
    " x = image.img_to_array(img)\n",
    " x = np.expand_dims(x,axis = 0)\n",
    " pred = model.predict(x)\n",
    " pred = pred[0][0]\n",
    " if pred > 0.5:\n",
    "   pred = 1\n",
    " else :\n",
    "    pred = 0\n",
    " print(pred)\n",
    " cv2.putText(frame,\"predicted class = \"+str(name[pred]),(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    " if pred==1:\n",
    "  account_sid = 'ACab5b7ac22466b88a9cda7cf5414b750a'\n",
    "  auth_token = 'c9c95130eade17e5e3d3f936283bef7a'\n",
    "  client = Client(account_sid, auth_token)\n",
    "  message = client.messages \\\n",
    "    .create(\n",
    "    body='Danger!Forest Fire is detected!',\n",
    "    from_='+17088477470',\n",
    "    to='+918825826199')\n",
    "  print(message.sid)\n",
    "  print(\"Fire detected\")\n",
    "  print(\"SMS Sent!\") \n",
    "  from playsound import playsound\n",
    "  playsound(r\"C:\\Users\\Dell\\Downloads\\alert alarm.wav\")\n",
    "  cv2.imshow('image',frame)\n",
    "  if cv2.waitKey(0)&0xFF == ord('a'):\n",
    "        break\n",
    " else:\n",
    "   print(\"No Danger\")\n",
    "   cv2.imshow('image',frame)\n",
    "   if cv2.waitKey(0)&0xFF == ord('a'):   \n",
    "        break\n",
    " video.release()       \n",
    " cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba583e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "video = cv2.VideoCapture(r\"C:\\Users\\Dell\\Downloads\\Wild fire.mp4\")\n",
    "name=['forest','with fire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c917ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "1\n",
      "SM7f8c0d730b291efe4bad93f913e44ecf\n",
      "Fire detected\n",
      "SMS Sent!\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:801: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      2\u001b[0m  success,frame \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m----> 3\u001b[0m  \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m  img \u001b[38;5;241m=\u001b[39m tensorflow\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mload_img(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,target_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m))\n\u001b[0;32m      5\u001b[0m  x \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:801: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    " success,frame = video.read()\n",
    " cv2.imwrite(\"image.jpg\",frame)\n",
    " img = tensorflow.keras.utils.load_img(\"image.jpg\",target_size = (128,128))\n",
    " x = image.img_to_array(img)\n",
    " x = np.expand_dims(x,axis = 0)\n",
    " pred = model.predict(x)\n",
    " pred = pred[0][0]\n",
    " if pred > 0.5:\n",
    "   pred = 1\n",
    " else :\n",
    "    pred = 0\n",
    " print(pred)\n",
    " cv2.putText(frame,\"predicted class = \"+str(name[pred]),(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    " if pred==1:\n",
    "  account_sid = 'ACab5b7ac22466b88a9cda7cf5414b750a'\n",
    "  auth_token = 'c9c95130eade17e5e3d3f936283bef7a'\n",
    "  client = Client(account_sid, auth_token)\n",
    "  message = client.messages \\\n",
    "    .create(\n",
    "    body='Forest Fire is detected,Stay alert',\n",
    "    from_='+17088477470',\n",
    "    to='+918825826199')\n",
    "  print(message.sid)\n",
    "  print(\"Fire detected\")\n",
    "  print(\"SMS Sent!\") \n",
    "  from playsound import playsound\n",
    "  playsound(r\"C:\\Users\\Dell\\Downloads\\alarm.mp3\")\n",
    "  cv2.imshow('image',frame)\n",
    "  if cv2.waitKey(0)&0xFF == ord('a'):\n",
    "        break\n",
    " else:\n",
    "   print(\"No Danger\")\n",
    "   cv2.imshow('image',frame)\n",
    "   if cv2.waitKey(0)&0xFF == ord('a'):   \n",
    "        break\n",
    " video.release()       \n",
    " cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d803d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
